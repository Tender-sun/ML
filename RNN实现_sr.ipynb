{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN实现-sr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiKpjfGXcgcMWKWwG9UI+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tender-sun/ML/blob/main/RNN%E5%AE%9E%E7%8E%B0_sr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 一、基于pytorch的实现"
      ],
      "metadata": {
        "id": "kWpmNXbU1Bwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "efDQ4N861Bey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        " \n",
        "device = torch.device('cuda')\n",
        " \n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(\n",
        "                input_size = 28,\n",
        "                hidden_size = 1,\n",
        "                num_layers = 1,\n",
        "                batch_first = True,\n",
        "        )\n",
        "        self.Out2Class = nn.Linear(28,10)\n",
        "    def forward(self, input):\n",
        "        output,hn = self.rnn(input,None)\n",
        "        # print('hn,shape:{}'.format(hn.shape))\n",
        "        outreshape = output[:,:,0]\n",
        "        # print(outreshape.shape)\n",
        "        tmp = self.Out2Class(outreshape)\n",
        "        # print(tmp.shape)\n",
        "        return tmp\n",
        " \n",
        " \n",
        "model = RNN()\n",
        "model = model.to(device)\n",
        "print(model)\n",
        " \n",
        " \n",
        " \n",
        "model = model.train()\n",
        " \n",
        "img_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                transforms.Normalize([0.5],[0.5])])\n",
        "dataset_train = datasets.MNIST(root = './data',transform = img_transform,train = True,download = True)\n",
        "dataset_test = datasets.MNIST(root = './data',transform = img_transform,train = False,download = True)\n",
        " \n",
        "train_loader = torch.utils.data.DataLoader(dataset = dataset_train,batch_size=64,shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = dataset_test,batch_size=64,shuffle = False)\n",
        " \n",
        "# images,label = next(iter(train_loader))\n",
        "# print(images.shape)\n",
        "# print(label.shape)\n",
        "# images_example = torchvision.utils.make_grid(images)\n",
        "# images_example = images_example.numpy().transpose(1,2,0)\n",
        "# mean = [0.5,0.5,0.5]\n",
        "# std = [0.5,0.5,0.5]\n",
        "# images_example = images_example*std + mean\n",
        "# plt.imshow(images_example)\n",
        "# plt.show()\n",
        " \n",
        "def Get_ACC():\n",
        "    correct = 0\n",
        "    total_num = len(dataset_test)\n",
        "    for item in test_loader:\n",
        "        batch_imgs,batch_labels = item\n",
        "        batch_imgs = batch_imgs.squeeze(1)\n",
        "        batch_imgs = Variable(batch_imgs)\n",
        "        batch_imgs = batch_imgs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        out = model(batch_imgs)\n",
        "        _,pred = torch.max(out.data,1)\n",
        "        correct += torch.sum(pred==batch_labels)\n",
        "    correct = correct.data.item()\n",
        "    acc = correct/total_num\n",
        "    print('correct={},Test ACC:{:.5}'.format(correct,acc))\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        " \n",
        "Get_ACC()\n",
        "for epoch in range(100):\n",
        "    print('epoch:{}'.format(epoch))\n",
        "    cnt = 0\n",
        "    for item in train_loader:\n",
        "        batch_imgs ,batch_labels = item\n",
        "        batch_imgs = batch_imgs.squeeze(1)\n",
        "        batch_imgs,batch_labels = Variable(batch_imgs),Variable(batch_labels)\n",
        "        batch_imgs = batch_imgs.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        out = model(batch_imgs)\n",
        "        loss = loss_f(out,batch_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if(cnt%100==0):\n",
        "            print_loss = loss.data.item()\n",
        "            #print('epoch:{},cnt:{},loss:{}'.format(epoch,cnt,print_loss))\n",
        "        cnt+=1\n",
        "    Get_ACC()\n",
        " \n",
        " \n",
        "torch.save(model,'model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78394bdd-6d95-4a29-aea3-cf491f5004ad",
        "id": "a0LdGTbF09UA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(28, 1, batch_first=True)\n",
            "  (Out2Class): Linear(in_features=28, out_features=10, bias=True)\n",
            ")\n",
            "correct=1019,Test ACC:0.1019\n",
            "epoch:0\n",
            "correct=6671,Test ACC:0.6671\n",
            "epoch:1\n",
            "correct=6886,Test ACC:0.6886\n",
            "epoch:2\n",
            "correct=6986,Test ACC:0.6986\n",
            "epoch:3\n",
            "correct=7043,Test ACC:0.7043\n",
            "epoch:4\n",
            "correct=7100,Test ACC:0.71\n",
            "epoch:5\n",
            "correct=7171,Test ACC:0.7171\n",
            "epoch:6\n",
            "correct=7209,Test ACC:0.7209\n",
            "epoch:7\n",
            "correct=7244,Test ACC:0.7244\n",
            "epoch:8\n",
            "correct=7289,Test ACC:0.7289\n",
            "epoch:9\n",
            "correct=7304,Test ACC:0.7304\n",
            "epoch:10\n",
            "correct=7333,Test ACC:0.7333\n",
            "epoch:11\n",
            "correct=7312,Test ACC:0.7312\n",
            "epoch:12\n",
            "correct=7366,Test ACC:0.7366\n",
            "epoch:13\n",
            "correct=7360,Test ACC:0.736\n",
            "epoch:14\n",
            "correct=7362,Test ACC:0.7362\n",
            "epoch:15\n",
            "correct=7381,Test ACC:0.7381\n",
            "epoch:16\n",
            "correct=7378,Test ACC:0.7378\n",
            "epoch:17\n",
            "correct=7409,Test ACC:0.7409\n",
            "epoch:18\n",
            "correct=7394,Test ACC:0.7394\n",
            "epoch:19\n",
            "correct=7418,Test ACC:0.7418\n",
            "epoch:20\n",
            "correct=7401,Test ACC:0.7401\n",
            "epoch:21\n",
            "correct=7429,Test ACC:0.7429\n",
            "epoch:22\n",
            "correct=7414,Test ACC:0.7414\n",
            "epoch:23\n",
            "correct=7427,Test ACC:0.7427\n",
            "epoch:24\n",
            "correct=7422,Test ACC:0.7422\n",
            "epoch:25\n",
            "correct=7449,Test ACC:0.7449\n",
            "epoch:26\n",
            "correct=7431,Test ACC:0.7431\n",
            "epoch:27\n",
            "correct=7436,Test ACC:0.7436\n",
            "epoch:28\n",
            "correct=7426,Test ACC:0.7426\n",
            "epoch:29\n",
            "correct=7443,Test ACC:0.7443\n",
            "epoch:30\n",
            "correct=7440,Test ACC:0.744\n",
            "epoch:31\n",
            "correct=7442,Test ACC:0.7442\n",
            "epoch:32\n",
            "correct=7468,Test ACC:0.7468\n",
            "epoch:33\n",
            "correct=7457,Test ACC:0.7457\n",
            "epoch:34\n",
            "correct=7476,Test ACC:0.7476\n",
            "epoch:35\n",
            "correct=7466,Test ACC:0.7466\n",
            "epoch:36\n",
            "correct=7459,Test ACC:0.7459\n",
            "epoch:37\n",
            "correct=7472,Test ACC:0.7472\n",
            "epoch:38\n",
            "correct=7435,Test ACC:0.7435\n",
            "epoch:39\n",
            "correct=7466,Test ACC:0.7466\n",
            "epoch:40\n",
            "correct=7491,Test ACC:0.7491\n",
            "epoch:41\n",
            "correct=7497,Test ACC:0.7497\n",
            "epoch:42\n",
            "correct=7475,Test ACC:0.7475\n",
            "epoch:43\n",
            "correct=7514,Test ACC:0.7514\n",
            "epoch:44\n",
            "correct=7527,Test ACC:0.7527\n",
            "epoch:45\n",
            "correct=7528,Test ACC:0.7528\n",
            "epoch:46\n",
            "correct=7542,Test ACC:0.7542\n",
            "epoch:47\n",
            "correct=7509,Test ACC:0.7509\n",
            "epoch:48\n",
            "correct=7521,Test ACC:0.7521\n",
            "epoch:49\n",
            "correct=7536,Test ACC:0.7536\n",
            "epoch:50\n",
            "correct=7516,Test ACC:0.7516\n",
            "epoch:51\n",
            "correct=7532,Test ACC:0.7532\n",
            "epoch:52\n",
            "correct=7551,Test ACC:0.7551\n",
            "epoch:53\n",
            "correct=7552,Test ACC:0.7552\n",
            "epoch:54\n",
            "correct=7542,Test ACC:0.7542\n",
            "epoch:55\n",
            "correct=7537,Test ACC:0.7537\n",
            "epoch:56\n",
            "correct=7527,Test ACC:0.7527\n",
            "epoch:57\n",
            "correct=7546,Test ACC:0.7546\n",
            "epoch:58\n",
            "correct=7558,Test ACC:0.7558\n",
            "epoch:59\n",
            "correct=7570,Test ACC:0.757\n",
            "epoch:60\n",
            "correct=7567,Test ACC:0.7567\n",
            "epoch:61\n",
            "correct=7560,Test ACC:0.756\n",
            "epoch:62\n",
            "correct=7560,Test ACC:0.756\n",
            "epoch:63\n",
            "correct=7562,Test ACC:0.7562\n",
            "epoch:64\n",
            "correct=7555,Test ACC:0.7555\n",
            "epoch:65\n",
            "correct=7586,Test ACC:0.7586\n",
            "epoch:66\n",
            "correct=7577,Test ACC:0.7577\n",
            "epoch:67\n",
            "correct=7561,Test ACC:0.7561\n",
            "epoch:68\n",
            "correct=7572,Test ACC:0.7572\n",
            "epoch:69\n",
            "correct=7578,Test ACC:0.7578\n",
            "epoch:70\n",
            "correct=7551,Test ACC:0.7551\n",
            "epoch:71\n",
            "correct=7572,Test ACC:0.7572\n",
            "epoch:72\n",
            "correct=7596,Test ACC:0.7596\n",
            "epoch:73\n",
            "correct=7588,Test ACC:0.7588\n",
            "epoch:74\n",
            "correct=7573,Test ACC:0.7573\n",
            "epoch:75\n",
            "correct=7559,Test ACC:0.7559\n",
            "epoch:76\n",
            "correct=7609,Test ACC:0.7609\n",
            "epoch:77\n",
            "correct=7598,Test ACC:0.7598\n",
            "epoch:78\n",
            "correct=7569,Test ACC:0.7569\n",
            "epoch:79\n",
            "correct=7569,Test ACC:0.7569\n",
            "epoch:80\n",
            "correct=7597,Test ACC:0.7597\n",
            "epoch:81\n",
            "correct=7579,Test ACC:0.7579\n",
            "epoch:82\n",
            "correct=7585,Test ACC:0.7585\n",
            "epoch:83\n",
            "correct=7600,Test ACC:0.76\n",
            "epoch:84\n",
            "correct=7599,Test ACC:0.7599\n",
            "epoch:85\n",
            "correct=7582,Test ACC:0.7582\n",
            "epoch:86\n",
            "correct=7590,Test ACC:0.759\n",
            "epoch:87\n",
            "correct=7599,Test ACC:0.7599\n",
            "epoch:88\n",
            "correct=7558,Test ACC:0.7558\n",
            "epoch:89\n",
            "correct=7595,Test ACC:0.7595\n",
            "epoch:90\n",
            "correct=7595,Test ACC:0.7595\n",
            "epoch:91\n",
            "correct=7582,Test ACC:0.7582\n",
            "epoch:92\n",
            "correct=7579,Test ACC:0.7579\n",
            "epoch:93\n",
            "correct=7615,Test ACC:0.7615\n",
            "epoch:94\n",
            "correct=7609,Test ACC:0.7609\n",
            "epoch:95\n",
            "correct=7590,Test ACC:0.759\n",
            "epoch:96\n",
            "correct=7609,Test ACC:0.7609\n",
            "epoch:97\n",
            "correct=7612,Test ACC:0.7612\n",
            "epoch:98\n",
            "correct=7614,Test ACC:0.7614\n",
            "epoch:99\n",
            "correct=7559,Test ACC:0.7559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 二、基于keras的实现"
      ],
      "metadata": {
        "id": "XOaesdBv1HZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        " \n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Activation, Dense\n",
        "from keras.optimizers import adam_v2\n",
        " \n",
        "TIME_STEPS = 28     # same as the height of the image\n",
        "INPUT_SIZE = 28     # same as the width of the image\n",
        "BATCH_SIZE = 64\n",
        "BATCH_INDEX = 0\n",
        "OUTPUT_SIZE = 10\n",
        "CELL_SIZE = 50\n",
        "LR = 0.001\n",
        "MAX_ITER=20001\n",
        " \n",
        " \n",
        "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
        "# X shape (60,000 28x28), y shape (10,000, )\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        " \n",
        "# data pre-processing\n",
        "X_train = X_train.reshape(-1, 28, 28) / 255.      # normalize\n",
        "X_test = X_test.reshape(-1, 28, 28) / 255.        # normalize\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
        " \n",
        "# build RNN model\n",
        "model = Sequential()\n",
        " \n",
        "# RNN cell\n",
        "model.add(SimpleRNN(\n",
        "    # for batch_input_shape, if using tensorflow as the backend, we have to put None for the batch_size.\n",
        "    # Otherwise, model.evaluate() will get error.\n",
        "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),       # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,\n",
        "    units=CELL_SIZE,\n",
        "    unroll=True,\n",
        "))\n",
        " \n",
        "# output layer\n",
        "model.add(Dense(OUTPUT_SIZE))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "# optimizer\n",
        "adam = adam_v2.Adam(LR)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# training\n",
        "for step in range(MAX_ITER):\n",
        "    # data shape = (batch_num, steps, inputs/outputs)\n",
        "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :, :]\n",
        "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX+BATCH_SIZE, :]\n",
        "    cost = model.train_on_batch(X_batch, Y_batch)\n",
        "    BATCH_INDEX += BATCH_SIZE\n",
        "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
        " \n",
        "    if step % 500 == 0:\n",
        "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
        "        print('iter = ',step,'test cost: ', cost, 'test accuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "ntSQy_ObwU6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a9a88a-6af9-4907-9d55-342bf1b6bb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "iter =  0 test cost:  2.4051592350006104 test accuracy:  0.10400000214576721\n",
            "iter =  500 test cost:  0.5619312524795532 test accuracy:  0.8371999859809875\n",
            "iter =  1000 test cost:  0.4255611300468445 test accuracy:  0.8729000091552734\n",
            "iter =  1500 test cost:  0.3316791355609894 test accuracy:  0.9056000113487244\n",
            "iter =  2000 test cost:  0.2989089787006378 test accuracy:  0.9156000018119812\n",
            "iter =  2500 test cost:  0.28790420293807983 test accuracy:  0.9168999791145325\n",
            "iter =  3000 test cost:  0.27327030897140503 test accuracy:  0.9217000007629395\n",
            "iter =  3500 test cost:  0.2863106429576874 test accuracy:  0.916700005531311\n",
            "iter =  4000 test cost:  0.2580949366092682 test accuracy:  0.9258000254631042\n",
            "iter =  4500 test cost:  0.2799329459667206 test accuracy:  0.9229999780654907\n",
            "iter =  5000 test cost:  0.20786210894584656 test accuracy:  0.9423999786376953\n",
            "iter =  5500 test cost:  0.21665668487548828 test accuracy:  0.9383999705314636\n",
            "iter =  6000 test cost:  0.19751273095607758 test accuracy:  0.9441999793052673\n",
            "iter =  6500 test cost:  0.2228395789861679 test accuracy:  0.9376999735832214\n",
            "iter =  7000 test cost:  0.23003095388412476 test accuracy:  0.9361000061035156\n",
            "iter =  7500 test cost:  0.35159364342689514 test accuracy:  0.8998000025749207\n",
            "iter =  8000 test cost:  0.20181837677955627 test accuracy:  0.9434999823570251\n",
            "iter =  8500 test cost:  0.20734448730945587 test accuracy:  0.9412999749183655\n",
            "iter =  9000 test cost:  0.18154871463775635 test accuracy:  0.9473999738693237\n",
            "iter =  9500 test cost:  0.1978655308485031 test accuracy:  0.9458000063896179\n",
            "iter =  10000 test cost:  0.16931121051311493 test accuracy:  0.9541000127792358\n",
            "iter =  10500 test cost:  0.20417213439941406 test accuracy:  0.9431999921798706\n",
            "iter =  11000 test cost:  0.1872137188911438 test accuracy:  0.9466000199317932\n",
            "iter =  11500 test cost:  0.17044921219348907 test accuracy:  0.9528999924659729\n",
            "iter =  12000 test cost:  0.16986294090747833 test accuracy:  0.9514999985694885\n",
            "iter =  12500 test cost:  0.1625489741563797 test accuracy:  0.9559000134468079\n",
            "iter =  13000 test cost:  0.17185907065868378 test accuracy:  0.9516000151634216\n",
            "iter =  13500 test cost:  0.17624762654304504 test accuracy:  0.9541000127792358\n",
            "iter =  14000 test cost:  0.15975776314735413 test accuracy:  0.955299973487854\n",
            "iter =  14500 test cost:  0.17999687790870667 test accuracy:  0.9491999745368958\n",
            "iter =  15000 test cost:  0.15210723876953125 test accuracy:  0.9585999846458435\n",
            "iter =  15500 test cost:  0.17538823187351227 test accuracy:  0.9516000151634216\n",
            "iter =  16000 test cost:  0.14695756137371063 test accuracy:  0.9599000215530396\n",
            "iter =  16500 test cost:  0.15056511759757996 test accuracy:  0.9596999883651733\n",
            "iter =  17000 test cost:  0.17149944603443146 test accuracy:  0.9549999833106995\n",
            "iter =  17500 test cost:  0.15590110421180725 test accuracy:  0.9549000263214111\n",
            "iter =  18000 test cost:  0.1662328690290451 test accuracy:  0.9531000256538391\n",
            "iter =  18500 test cost:  0.15169599652290344 test accuracy:  0.9592000246047974\n",
            "iter =  19000 test cost:  0.14260363578796387 test accuracy:  0.9631999731063843\n",
            "iter =  19500 test cost:  0.14306694269180298 test accuracy:  0.9599000215530396\n",
            "iter =  20000 test cost:  0.14097878336906433 test accuracy:  0.9610999822616577\n"
          ]
        }
      ]
    }
  ]
}